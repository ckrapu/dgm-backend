{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.0-rc0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_probability as tfp\n",
    "import time \n",
    "tfd = tfp.distributions\n",
    "tfp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "FROM_LOGITS = True\n",
    "\n",
    "model_path   = '../data/saved_models/vae_mnist_generative_net.h5'\n",
    "test_path    = '../data/datasets/test/mnist_single.npy'\n",
    "mcmc_kernel  = tfp.mcmc.HamiltonianMonteCarlo\n",
    "mcmc_kwargs  = {}\n",
    "n_chains     = 100\n",
    "\n",
    "\n",
    "# Import models \n",
    "generator  = tf.keras.models.load_model(model_path)\n",
    "latent_dim = generator.input_shape[-1]\n",
    "z_shape    = [n_chains, latent_dim]\n",
    "shape_single_draw = [latent_dim]\n",
    "\n",
    "# Import test data\n",
    "test = np.load(test_path, allow_pickle=True)\n",
    "x_true = test.data.repeat(n_chains,axis=0)\n",
    "mask = (1 - test.mask).repeat(n_chains,axis=0)\n",
    "#x_true = tf.cast(test.data,'float32')\n",
    "#mask   = (1-test.mask)\n",
    "\n",
    "# Prepare log prior function\n",
    "prior_sd          = 1\n",
    "\n",
    "ind = tfd.Independent(\n",
    "    distribution=tfd.MultivariateNormalDiag(\n",
    "        loc=tf.zeros(z_shape),\n",
    "        scale_identity_multiplier=prior_sd))\n",
    "\n",
    "log_prior = ind.log_prob\n",
    "\n",
    "\n",
    "# Prepare log likelihood function\n",
    "def log_like(z):\n",
    "    x_pred = generator(z)\n",
    "        \n",
    "    raw_loss = tf.keras.losses.binary_crossentropy(x_true,\n",
    "                                               x_pred,\n",
    "                                               from_logits=FROM_LOGITS) \n",
    "    loss = tf.expand_dims(raw_loss,-1) * mask\n",
    "    ll = tf.reduce_sum(loss,axis=[1,2,3])\n",
    "    return ll\n",
    "    \n",
    "# Create target log density\n",
    "def log_prob(z):\n",
    "    return log_prior(z) + log_like(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_temperatures = np.exp(np.linspace(1,-2,100)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "    tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=log_prob,\n",
    "        num_leapfrog_steps=8,\n",
    "        step_size=1.),\n",
    "    num_adaptation_steps=int(num_burnin_steps * 0.8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chain (with burn-in).\n",
    "@tf.function\n",
    "def run_chain(kernel,n_samples,n_burnin):\n",
    "  # Run the chain (with burn-in).\n",
    "    samples, is_accepted = tfp.mcmc.sample_chain(\n",
    "      num_results=n_samples,\n",
    "      num_burnin_steps=n_burnin,\n",
    "      current_state = np.random.randn(*z_shape).astype('float32'),\n",
    "      kernel=kernel,\n",
    "      parallel_iterations = n_chains,\n",
    "    )\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/sample.py:335: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
      "  warnings.warn(\"Tracing all kernel results by default is deprecated. Set \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/replica_exchange_mc.py:385: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "num_results = 100\n",
    "num_burnin_steps = 100\n",
    "total_iter = num_results + num_burnin_steps\n",
    "samples = run_chain(remc,num_results,num_burnin_steps)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "rate = total_iter/total\n",
    "print(f'{rate} samples drawn per second.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/sample.py:335: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
      "  warnings.warn(\"Tracing all kernel results by default is deprecated. Set \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.448367300124692 samples drawn per second.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "num_results = 100\n",
    "num_burnin_steps = 100\n",
    "total_iter = num_results + num_burnin_steps\n",
    "samples = run_chain(adaptive_hmc,num_results,num_burnin_steps)\n",
    "end = time.time()\n",
    "total = end - start\n",
    "rate = total_iter/total\n",
    "print(f'{rate} samples drawn per second.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_x = np.zeros([samples.shape[0],samples.shape[1],28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(sampled_x.shape[0]):\n",
    "    sampled_x[i] = tf.math.sigmoid(generator(samples[i])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from visualize import samples2gif\n",
    "\n",
    "output_path = '../data/visualizations/hmc_chain.gif'\n",
    "samples2gif(sampled_x[::500], output_path, 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "for i in np.linspace(0,num_results-1,10):\n",
    "    idx = int(i)\n",
    "    plt.figure()\n",
    "    x = tf.math.sigmoid(generator(samples[idx])).numpy().squeeze()\n",
    "    plt.imshow(utils.flatten_image_batch(x,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../data/visualizations/hmc_chain.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"../data/visualizations/hmc_chain.gif\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
